{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bastion AI Real World Example\n",
    "## Finetuning DistilBERT for binary classification on the SMS Spam Collection\n",
    "\n",
    "Data preparation and training are largely based on https://towardsdatascience.com/fine-tuning-bert-for-text-classification-54e7df642894.\n",
    "\n",
    "### Installing Bastion AI\n",
    "\n",
    "To use this notebook, you'll need a working Bastion AI installation.\n",
    "First clone our repo:\n",
    "```\n",
    "$ git clone git@github.com:mithril-security/bastionai.git\n",
    "```\n",
    "Then install the client library:\n",
    "```\n",
    "$ cd ./bastionai/client\n",
    "$ make install\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing and importing additionnal packages\n",
    "\n",
    "Let's first import all the necessary packages for the entire notebook.\n",
    "The makefile for the client has already set up a virtualenv with the client dependences for us.\n",
    "We just need to install the additionnal packages we'll use:\n",
    "\n",
    "```\n",
    "$ source venv/bin/activate\n",
    "$ pip install transformers pandas sklearn ipykernel ipywidgets\n",
    "```\n",
    "\n",
    "We can now import necessary packages and objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "\n",
    "from bastionai.client import Connection\n",
    "from bastionai.psg import expand_weights\n",
    "from bastionai.utils import MultipleOutputWrapper, TensorDataset\n",
    "from bastionai.pb.remote_torch_pb2 import TestConfig, TrainConfig, Empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the dataset\n",
    "\n",
    "The dataset can be found at https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip.\n",
    "Unzip the archive to obtain the datset file:\n",
    "\n",
    "```\n",
    "$ unzip smsspamcollection.zip\n",
    "```\n",
    "\n",
    "Each row represent a sample, the label come first followed by a tab and the raw text:\n",
    "```\n",
    "ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
    "ham\tOk lar... Joking wif u oni...\n",
    "spam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
    "```\n",
    "\n",
    "We first load the data from the file into a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                    Ok lar... Joking wif u oni...\\n\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"../tests/data/SMSSpamCollection\"\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "with open(file_path) as f:\n",
    "  for line in f.readlines():\n",
    "    split = line.split('\\t')\n",
    "    labels.append(1 if split[0] == \"spam\" else 0)\n",
    "    texts.append(split[1])\n",
    "df = pd.DataFrame({ \"label\": labels, \"text\": texts })\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then preprocess the data using DistilBERT's tokenizer and we obtain tensors ready to be fed to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "token_id = []\n",
    "attention_masks = []\n",
    "for sample in df.text.values:\n",
    "    encoding_dict = tokenizer.encode_plus(\n",
    "        sample,\n",
    "        add_special_tokens=True,\n",
    "        max_length=32,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    token_id.append(encoding_dict['input_ids']) \n",
    "    attention_masks.append(encoding_dict['attention_mask'])\n",
    "\n",
    "token_id = torch.cat(token_id, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(df.label.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's now time to split the data in a train and test sets and to wrap it inside Dataset object for ease of use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ratio = 0.2\n",
    "\n",
    "train_idx, test_idx = train_test_split(\n",
    "    np.arange(len(labels)),\n",
    "    test_size=val_ratio,\n",
    "    shuffle=True,\n",
    "    stratify=labels\n",
    ")\n",
    "\n",
    "train_set = TensorDataset([\n",
    "    token_id[train_idx], \n",
    "    attention_masks[train_idx]\n",
    "], labels[train_idx])\n",
    "\n",
    "test_set = TensorDataset([\n",
    "    token_id[test_idx], \n",
    "    attention_masks[test_idx]\n",
    "], labels[test_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the model for use with DP-SGD and Bastion AI\n",
    "\n",
    "We now turn to preparing the DistilBERT language model. As training will be executed remotely on a private Bastion AI server, we need to script the model prior to sending it (i.e. compile it to Torch Script).\n",
    "\n",
    "In addition, as we'll use the DP-SGD algorithm for training in this example, we need to make the model compatible with Bastion AI's DP-SGD implementation. Unlike Opacus that uses backprop hooks to compute per-sample gradients, Bastion AI relies on normal autograd and modified layers that internally store expanded gradients (weight tensors have the same size in memory but are manipulated through expanded views that repeat them as many times as there are samples in a batch so that the gradient of these views are per-sample gradients).\n",
    "\n",
    "Per-samples gradient computation is key to DP-SGD and is one ingredient that make DP usable with Deep Learning models. Fortunately, we don't need to redifine the DistilBERT architecture to switch layers, Bastion AI includes a utility function that does this tedious job for us. Note that weights must be exapanded prior to scripting the model for changes to also apply on the server side.\n",
    "\n",
    "As Hugging Face's models were not designed with scripting in mind, we must resort to tracing them to obtain a Torch Script version of them. The model is run with a dummy but representative input and the torch jit compiler tracks all functions that are called and compiles them on the fly. This approach, although more error prone (in certain cases the dummy input may not activate some needed computation paths) is less picky that scripting and accepts our model.\n",
    "\n",
    "Note that we also need to use Bastion AI's utility wrapper for models with multiple outputs to select the sole output that corresponds with the logits. In fact, Bastion AI's server supports models with an arbitrtary number of inputs and a single output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not display warnings about layer not initialized\n",
    "# with pretrained weights (classification layers, this is fine)\n",
    "# nor warnings originating from torch.jit.trace\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased',\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    "    torchscript=True\n",
    ")\n",
    "expand_weights(model, batch_size) # Convert learnable layers into their expanded counterparts\n",
    "\n",
    "[text, mask], label = train_set[0] # Dummy input used to trace the model\n",
    "traced_model = torch.jit.trace( # Compile the model with the tracing strategy\n",
    "    MultipleOutputWrapper(model, 0), # Wrapp the model to use the first output only (and drop the others)\n",
    "    [\n",
    "        text.unsqueeze(0),\n",
    "        mask.unsqueeze(0)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sending dataset and model and training on the server\n",
    "\n",
    "Before proceeding, we need to start a local Bastion AI server which can be achivied with the following commands,\n",
    "assuming you have a working rust toolchain (https://www.rust-lang.org/tools/install):\n",
    "\n",
    "```\n",
    "$ cd ../server/bastionai_app\n",
    "$ cargo run\n",
    "```\n",
    "\n",
    "Now that the server code has been compiled and the server has started, it's time to send the dataset and the model to the server.\n",
    "\n",
    "In both cases, the API returns a reference to the object (a UUID).\n",
    "\n",
    "We can use these to reference the objects in the subsequent calls such as when training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ref: identifier: \"0a0f8333-18c0-447d-816c-aff824eec279\"\n",
      "description: \"Expanded DistilBERT\"\n",
      "\n",
      "Dataset ref: identifier: \"e9c0fc3b-fe1d-4c41-99d8-134969f0d3de\"\n",
      "description: \"SMSSpamCollection\"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 - train:   0%|                    | 4/1114 [00:04<29:53,  1.62s/batch, loss (cross_entropy)=0.6127] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m train_dataset_ref \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39msend_dataset(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     train_set,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mSMSSpamCollection\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39msecret\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDataset ref: \u001b[39m\u001b[39m{\u001b[39;00mtrain_dataset_ref\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m client\u001b[39m.\u001b[39;49mtrain(TrainConfig(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     model\u001b[39m=\u001b[39;49mmodel_ref,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     dataset\u001b[39m=\u001b[39;49mtrain_dataset_ref,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     device\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     metric\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcross_entropy\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     differential_privacy\u001b[39m=\u001b[39;49mTrainConfig\u001b[39m.\u001b[39;49mDpParameters(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         max_grad_norm\u001b[39m=\u001b[39;49m\u001b[39m100.\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m         noise_multiplier\u001b[39m=\u001b[39;49m\u001b[39m0.001\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     ),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39m# standard=Empty(),\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     adam\u001b[39m=\u001b[39;49mTrainConfig\u001b[39m.\u001b[39;49mAdam(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m         learning_rate\u001b[39m=\u001b[39;49m\u001b[39m5e-5\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m         beta_1\u001b[39m=\u001b[39;49m\u001b[39m0.9\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m         beta_2\u001b[39m=\u001b[39;49m\u001b[39m0.999\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m         epsilon\u001b[39m=\u001b[39;49m\u001b[39m1e-8\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m         weight_decay\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m         amsgrad\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m ))\n",
      "File \u001b[0;32m~/Documents/bastionai/client/src/bastionai/client.py:123\u001b[0m, in \u001b[0;36mClient.train\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m, config: TrainConfig) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m     \u001b[39m\"\"\"Trains a model with `TrainConfig` configuration on BastionAI.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \n\u001b[1;32m    119\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[39m        config (TrainConfig):\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[39m            Training configuration to pass to BastionAI.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     metric_tqdm_with_epochs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstub\u001b[39m.\u001b[39;49mTrain(\n\u001b[1;32m    124\u001b[0m         config), name\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mloss (\u001b[39;49m\u001b[39m{\u001b[39;49;00mconfig\u001b[39m.\u001b[39;49mmetric\u001b[39m}\u001b[39;49;00m\u001b[39m)\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/bastionai/client/src/bastionai/utils.py:273\u001b[0m, in \u001b[0;36mmetric_tqdm_with_epochs\u001b[0;34m(metric_stream, name)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n\u001b[1;32m    272\u001b[0m t \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 273\u001b[0m \u001b[39mfor\u001b[39;00m metric \u001b[39min\u001b[39;00m metric_stream:\n\u001b[1;32m    274\u001b[0m     \u001b[39mif\u001b[39;00m t \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    275\u001b[0m         t \u001b[39m=\u001b[39m new_tqdm_bar(\u001b[39m1\u001b[39m, metric\u001b[39m.\u001b[39mnb_epochs, metric\u001b[39m.\u001b[39mnb_batches)\n",
      "File \u001b[0;32m~/Documents/bastionai/client/venv/lib/python3.10/site-packages/grpc/_channel.py:426\u001b[0m, in \u001b[0;36m_Rendezvous.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 426\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next()\n",
      "File \u001b[0;32m~/Documents/bastionai/client/venv/lib/python3.10/site-packages/grpc/_channel.py:817\u001b[0m, in \u001b[0;36m_MultiThreadedRendezvous._next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_response_ready\u001b[39m():\n\u001b[1;32m    812\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state\u001b[39m.\u001b[39mresponse \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m\n\u001b[1;32m    813\u001b[0m             (cygrpc\u001b[39m.\u001b[39mOperationType\u001b[39m.\u001b[39mreceive_message\n\u001b[1;32m    814\u001b[0m              \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state\u001b[39m.\u001b[39mdue \u001b[39mand\u001b[39;00m\n\u001b[1;32m    815\u001b[0m              \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state\u001b[39m.\u001b[39mcode \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m--> 817\u001b[0m _common\u001b[39m.\u001b[39;49mwait(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_state\u001b[39m.\u001b[39;49mcondition\u001b[39m.\u001b[39;49mwait, _response_ready)\n\u001b[1;32m    818\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state\u001b[39m.\u001b[39mresponse \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    819\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state\u001b[39m.\u001b[39mresponse\n",
      "File \u001b[0;32m~/Documents/bastionai/client/venv/lib/python3.10/site-packages/grpc/_common.py:141\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(wait_fn, wait_complete_fn, timeout, spin_cb)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m wait_complete_fn():\n\u001b[0;32m--> 141\u001b[0m         _wait_once(wait_fn, MAXIMUM_WAIT_TIMEOUT, spin_cb)\n\u001b[1;32m    142\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m+\u001b[39m timeout\n",
      "File \u001b[0;32m~/Documents/bastionai/client/venv/lib/python3.10/site-packages/grpc/_common.py:106\u001b[0m, in \u001b[0;36m_wait_once\u001b[0;34m(wait_fn, timeout, spin_cb)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wait_once\u001b[39m(wait_fn, timeout, spin_cb):\n\u001b[0;32m--> 106\u001b[0m     wait_fn(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    107\u001b[0m     \u001b[39mif\u001b[39;00m spin_cb \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    108\u001b[0m         spin_cb()\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[1;32m    325\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with Connection(\"localhost\", 50051) as client:\n",
    "    model_ref = client.send_model(\n",
    "        traced_model,\n",
    "        \"Expanded DistilBERT\",\n",
    "        b\"secret\"\n",
    "    )\n",
    "    print(f\"Model ref: {model_ref}\")\n",
    "\n",
    "    train_dataset_ref = client.send_dataset(\n",
    "        train_set,\n",
    "        \"SMSSpamCollection\",\n",
    "        b'secret'\n",
    "    )\n",
    "    print(f\"Dataset ref: {train_dataset_ref}\")\n",
    "\n",
    "    client.train(TrainConfig(\n",
    "        model=model_ref,\n",
    "        dataset=train_dataset_ref,\n",
    "        batch_size=batch_size,\n",
    "        epochs=2,\n",
    "        device=\"cpu\",\n",
    "        metric=\"cross_entropy\",\n",
    "        differential_privacy=TrainConfig.DpParameters(\n",
    "            max_grad_norm=100.,\n",
    "            noise_multiplier=0.001\n",
    "        ),\n",
    "        # standard=Empty(),\n",
    "        adam=TrainConfig.Adam(\n",
    "            learning_rate=5e-5,\n",
    "            beta_1=0.9,\n",
    "            beta_2=0.999,\n",
    "            epsilon=1e-8,\n",
    "            weight_decay=0,\n",
    "            amsgrad=False\n",
    "        )\n",
    "    ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6993cb9073eaa1097b6e3b6529d06c5840b05bad16c8a47177ac9bf16f0b1e0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
