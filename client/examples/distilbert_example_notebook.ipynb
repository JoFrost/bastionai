{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bastion AI Real World Example\n",
    "## Finetuning DistilBERT for binary classification on the SMS Spam Collection\n",
    "\n",
    "Data preparation and training are largely based on https://towardsdatascience.com/fine-tuning-bert-for-text-classification-54e7df642894.\n",
    "\n",
    "### Installing Bastion AI\n",
    "\n",
    "To use this notebook, you'll need a working Bastion AI installation.\n",
    "First clone our repo:\n",
    "```\n",
    "$ git clone git@github.com:mithril-security/bastionai.git\n",
    "```\n",
    "Then install the client library:\n",
    "```\n",
    "$ cd ./bastionai/client\n",
    "$ make install\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing and importing additionnal packages\n",
    "\n",
    "Let's first import all the necessary packages for the entire notebook.\n",
    "The makefile for the client has already set up a virtualenv with the client dependences for us.\n",
    "We just need to install the additionnal packages we'll use:\n",
    "\n",
    "```\n",
    "$ source venv/bin/activate\n",
    "$ pip install transformers pandas sklearn ipykernel ipywidgets\n",
    "```\n",
    "\n",
    "We can now import necessary packages and objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "\n",
    "from bastionai.client import Connection\n",
    "from bastionai.psg import expand_weights\n",
    "from bastionai.utils import MultipleOutputWrapper, TensorDataset\n",
    "from bastionai.pb.remote_torch_pb2 import TestConfig, TrainConfig, Empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the dataset\n",
    "\n",
    "The dataset can be found at https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip.\n",
    "Unzip the archive to obtain the datset file:\n",
    "\n",
    "```\n",
    "$ unzip smsspamcollection.zip\n",
    "```\n",
    "\n",
    "Each row represent a sample, the label come first followed by a tab and the raw text:\n",
    "```\n",
    "ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
    "ham\tOk lar... Joking wif u oni...\n",
    "spam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
    "```\n",
    "\n",
    "We first load the data from the file into a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                    Ok lar... Joking wif u oni...\\n\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"../tests/data/SMSSpamCollection\"\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "with open(file_path) as f:\n",
    "  for line in f.readlines():\n",
    "    split = line.split('\\t')\n",
    "    labels.append(1 if split[0] == \"spam\" else 0)\n",
    "    texts.append(split[1])\n",
    "df = pd.DataFrame({ \"label\": labels, \"text\": texts })\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then preprocess the data using DistilBERT's tokenizer and we obtain tensors ready to be fed to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "token_id = []\n",
    "attention_masks = []\n",
    "for sample in df.text.values:\n",
    "    encoding_dict = tokenizer.encode_plus(\n",
    "        sample,\n",
    "        add_special_tokens=True,\n",
    "        max_length=32,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    token_id.append(encoding_dict['input_ids']) \n",
    "    attention_masks.append(encoding_dict['attention_mask'])\n",
    "\n",
    "token_id = torch.cat(token_id, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(df.label.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's now time to split the data in a train and test sets and to wrap it inside Dataset object for ease of use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ratio = 0.2\n",
    "\n",
    "train_idx, test_idx = train_test_split(\n",
    "    np.arange(len(labels)),\n",
    "    test_size=val_ratio,\n",
    "    shuffle=True,\n",
    "    stratify=labels\n",
    ")\n",
    "\n",
    "train_set = TensorDataset([\n",
    "    token_id[train_idx], \n",
    "    attention_masks[train_idx]\n",
    "], labels[train_idx])\n",
    "\n",
    "test_set = TensorDataset([\n",
    "    token_id[test_idx], \n",
    "    attention_masks[test_idx]\n",
    "], labels[test_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the model for use with DP-SGD and Bastion AI\n",
    "\n",
    "We now turn to preparing the DistilBERT language model. As training will be executed remotely on a private Bastion AI server, we need to script the model prior to sending it (i.e. compile it to Torch Script).\n",
    "\n",
    "In addition, as we'll use the DP-SGD algorithm for training in this example, we need to make the model compatible with Bastion AI's DP-SGD implementation. Unlike Opacus that uses backprop hooks to compute per-sample gradients, Bastion AI relies on normal autograd and modified layers that internally store expanded gradients (weight tensors have the same size in memory but are manipulated through expanded views that repeat them as many times as there are samples in a batch so that the gradient of these views are per-sample gradients).\n",
    "\n",
    "Per-samples gradient computation is key to DP-SGD and is one ingredient that make DP usable with Deep Learning models. Fortunately, we don't need to redifine the DistilBERT architecture to switch layers, Bastion AI includes a utility function that does this tedious job for us. Note that weights must be exapanded prior to scripting the model for changes to also apply on the server side.\n",
    "\n",
    "As Hugging Face's models were not designed with scripting in mind, we must resort to tracing them to obtain a Torch Script version of them. The model is run with a dummy but representative input and the torch jit compiler tracks all functions that are called and compiles them on the fly. This approach, although more error prone (in certain cases the dummy input may not activate some needed computation paths) is less picky that scripting and accepts our model.\n",
    "\n",
    "Note that we also need to use Bastion AI's utility wrapper for models with multiple outputs to select the sole output that corresponds with the logits. In fact, Bastion AI's server supports models with an arbitrtary number of inputs and a single output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not display warnings about layer not initialized\n",
    "# with pretrained weights (classification layers, this is fine)\n",
    "# nor warnings originating from torch.jit.trace\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased',\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    "    torchscript=True\n",
    ")\n",
    "expand_weights(model, batch_size) # Convert learnable layers into their expanded counterparts\n",
    "\n",
    "[text, mask], label = train_set[0] # Dummy input used to trace the model\n",
    "traced_model = torch.jit.trace( # Compile the model with the tracing strategy\n",
    "    MultipleOutputWrapper(model, 0), # Wrapp the model to use the first output only (and drop the others)\n",
    "    [\n",
    "        text.unsqueeze(0),\n",
    "        mask.unsqueeze(0)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sending dataset and model and training on the server\n",
    "\n",
    "Before proceeding, we need to start a local Bastion AI server which can be achivied with the following commands,\n",
    "assuming you have a working rust toolchain (https://www.rust-lang.org/tools/install):\n",
    "\n",
    "```\n",
    "$ cd ../server/bastionai_app\n",
    "$ cargo run\n",
    "```\n",
    "\n",
    "Now that the server code has been compiled and the server has started, it's time to send the dataset and the model to the server.\n",
    "\n",
    "In both cases, the API returns a reference to the object (a UUID).\n",
    "\n",
    "We can use these to reference the objects in the subsequent calls such as when training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "_InactiveRpcError",
     "evalue": "<_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"failed to connect to all addresses\"\n\tdebug_error_string = \"{\"created\":\"@1660301475.618716534\",\"description\":\"Failed to pick subchannel\",\"file\":\"src/core/ext/filters/client_channel/client_channel.cc\",\"file_line\":3260,\"referenced_errors\":[{\"created\":\"@1660301475.618716277\",\"description\":\"failed to connect to all addresses\",\"file\":\"src/core/lib/transport/error_utils.cc\",\"file_line\":167,\"grpc_status\":14}]}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m Connection(\u001b[39m\"\u001b[39m\u001b[39mlocalhost\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m50051\u001b[39m) \u001b[39mas\u001b[39;00m client:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     model_ref \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49msend_model(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         traced_model,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mExpanded DistilBERT\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msecret\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     )\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel ref: \u001b[39m\u001b[39m{\u001b[39;00mmodel_ref\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     train_dataset_ref \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39msend_dataset(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         train_set,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSMSSpamCollection\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39msecret\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/client/examples/distilbert_example_notebook.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/bastionai/client/src/bastionai/client.py:38\u001b[0m, in \u001b[0;36mClient.send_model\u001b[0;34m(self, model, description, secret, chunk_size)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msend_model\u001b[39m(\u001b[39mself\u001b[39m, model: Module, description: \u001b[39mstr\u001b[39m, secret: \u001b[39mbytes\u001b[39m, chunk_size\u001b[39m=\u001b[39m\u001b[39m100_000_000\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Reference:\n\u001b[1;32m     21\u001b[0m     \u001b[39m\"\"\"Uploads Pytorch Modules to BastionAI\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \u001b[39m    This endpoint transforms Pytorch modules into TorchScript modules and sends\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39m            BastionAI reference object\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstub\u001b[39m.\u001b[39;49mSendModel(serialize_model(model, description\u001b[39m=\u001b[39;49mdescription, secret\u001b[39m=\u001b[39;49msecret, chunk_size\u001b[39m=\u001b[39;49mchunk_size))\n",
      "File \u001b[0;32m~/Documents/bastionai/client/venv/lib/python3.10/site-packages/grpc/_channel.py:1131\u001b[0m, in \u001b[0;36m_StreamUnaryMultiCallable.__call__\u001b[0;34m(self, request_iterator, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1122\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m   1123\u001b[0m              request_iterator,\n\u001b[1;32m   1124\u001b[0m              timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1127\u001b[0m              wait_for_ready\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1128\u001b[0m              compression\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1129\u001b[0m     state, call, \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blocking(request_iterator, timeout, metadata,\n\u001b[1;32m   1130\u001b[0m                                   credentials, wait_for_ready, compression)\n\u001b[0;32m-> 1131\u001b[0m     \u001b[39mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[39mFalse\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Documents/bastionai/client/venv/lib/python3.10/site-packages/grpc/_channel.py:849\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[39mreturn\u001b[39;00m state\u001b[39m.\u001b[39mresponse\n\u001b[1;32m    848\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 849\u001b[0m     \u001b[39mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"failed to connect to all addresses\"\n\tdebug_error_string = \"{\"created\":\"@1660301475.618716534\",\"description\":\"Failed to pick subchannel\",\"file\":\"src/core/ext/filters/client_channel/client_channel.cc\",\"file_line\":3260,\"referenced_errors\":[{\"created\":\"@1660301475.618716277\",\"description\":\"failed to connect to all addresses\",\"file\":\"src/core/lib/transport/error_utils.cc\",\"file_line\":167,\"grpc_status\":14}]}\"\n>"
     ]
    }
   ],
   "source": [
    "with Connection(\"localhost\", 50051) as client:\n",
    "    model_ref = client.send_model(\n",
    "        traced_model,\n",
    "        \"Expanded DistilBERT\",\n",
    "        b\"secret\"\n",
    "    )\n",
    "    print(f\"Model ref: {model_ref}\")\n",
    "\n",
    "    train_dataset_ref = client.send_dataset(\n",
    "        train_set,\n",
    "        \"SMSSpamCollection\",\n",
    "        b'secret'\n",
    "    )\n",
    "    print(f\"Dataset ref: {train_dataset_ref}\")\n",
    "\n",
    "    client.train(TrainConfig(\n",
    "        model=model_ref,\n",
    "        dataset=train_dataset_ref,\n",
    "        batch_size=batch_size,\n",
    "        epochs=2,\n",
    "        device=\"cpu\",\n",
    "        metric=\"cross_entropy\",\n",
    "        differential_privacy=TrainConfig.DpParameters(\n",
    "            max_grad_norm=100.,\n",
    "            noise_multiplier=0.001\n",
    "        ),\n",
    "        # standard=Empty(),\n",
    "        adam=TrainConfig.Adam(\n",
    "            learning_rate=5e-5,\n",
    "            beta_1=0.9,\n",
    "            beta_2=0.999,\n",
    "            epsilon=1e-8,\n",
    "            weight_decay=0,\n",
    "            amsgrad=False\n",
    "        )\n",
    "    ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6993cb9073eaa1097b6e3b6529d06c5840b05bad16c8a47177ac9bf16f0b1e0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
