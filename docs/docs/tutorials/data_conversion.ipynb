{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"colab_button\">\n",
    "  <h1>Data Conversion within BastionLab</h1>\n",
    "  <a target=\"_blank\" href=\"https://colab.research.google.com/github/mithril-security/bastionlab/blob/v0.3.7/docs/docs/tutorials/SQL_queries.ipynb\"> \n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "</div>\n",
    "__________________________________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for BastionLab to be a one-stop shop for data exploration, deep learning training and machine learning model fitting, it's important that we are able to convert remote data to respective representations to exploit BastionLab full capabilities."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial introduces simply how you can convert a `RemoteDataFrame`s to `RemoteTensor`s and use them for your deep learning model training."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites\n",
    "___________________________________________\n",
    "\n",
    "### Installation and dataset\n",
    "\n",
    "In order to run this notebook, we need to:\n",
    "- Have [Python3.7](https://www.python.org/downloads/) (or greater) and [Python Pip](https://pypi.org/project/pip/) installed\n",
    "- Install [BastionLab](https://bastionlab.readthedocs.io/en/latest/docs/getting-started/installation/)\n",
    "- Download [the dataset](https://www.kaggle.com/competitions/titanic) we will be using in this tutorial.\n",
    "- PyTorch [1.13.1](https://pypi.org/project/torch/) installed\n",
    "\n",
    "We'll do so by running the code block below. \n",
    "\n",
    ">If you are running this notebook on your machine instead of [Google Colab](https://colab.research.google.com/github/mithril-security/bastionlab/blob/v0.3.6/docs/docs/tutorials/data_cleaning.ipynb), you can see our [Installation page](https://bastionlab.readthedocs.io/en/latest/docs/getting-started/installation/) to find the installation method that best suits your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip packages\n",
    "!pip install bastionlab\n",
    "!pip install bastionlab_server\n",
    "\n",
    "# download the dataset\n",
    "!wget 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is based on the [Titanic dataset](https://www.kaggle.com/c/titanic), one of the most popular ressource used for understanding machine learning, which contains information relating to the passengers aboard the Titanic. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch and connect to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch bastionlab_server test package\n",
    "import bastionlab_server\n",
    "\n",
    "srv = bastionlab_server.start()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*Note that the bastionlab_server package we install here was created for testing purposes. You can also install BastionLab server using our Docker image or from source (especially for non-test purposes). Check out our [Installation Tutorial](../getting-started/installation.md) for more details.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbamponsem/base/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# connect to the server\n",
    "from bastionlab import Connection\n",
    "\n",
    "connection = Connection(\"localhost\")\n",
    "client = connection.client"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the dataframe to the server\n",
    "\n",
    "Before we upload the dataset to the server, we'll create a custom privacy policy which allows all operations to be done on the dataframe. *You can check out how to define a privacy policy [here](https://bastionlab.readthedocs.io/en/latest/docs/tutorials/defining_policy_privacy/).* \n",
    "\n",
    "We also limit the size of the dataset sent to the server because in this tutorial, we are only performing data conversion and not really data exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FetchableLazyFrame(identifier=600f8b6d-2a7c-4363-97cb-cce0055cf65d)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "from bastionlab.polars.policy import Policy, TrueRule, Log\n",
    "\n",
    "df = pl.read_csv(\"titanic.csv\")\n",
    "policy = Policy(safe_zone=TrueRule, unsafe_handling=Log(), savable=False)\n",
    "rdf = client.polars.send_df(df.limit(100), policy=policy)\n",
    "\n",
    "rdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert RemoteDataFrames to RemoteArray\n",
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RemoteArray`s are BastionLab's internal intermediate representations which are akin to numpy arrays but are essentially pointers to a `DataFrame` on the server which when `to_tensor` is called converts the `DataFrame` to `Tensor` on the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "no_execute"
    ]
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Utf8 column cannot be converted into RemoteArray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rdf\u001b[39m.\u001b[39;49mto_array()\n",
      "File \u001b[0;32m~/Projects/bastionlab/client/src/bastionlab/polars/remote_polars.py:324\u001b[0m, in \u001b[0;36mRemoteLazyFrame.to_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_array\u001b[39m(\u001b[39mself\u001b[39m: LDF) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mRemoteArray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m     \u001b[39mreturn\u001b[39;00m RemoteArray(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/Projects/bastionlab/client/src/bastionlab/polars/remote_polars.py:1454\u001b[0m, in \u001b[0;36mRemoteArray.__init__\u001b[0;34m(self, rdf)\u001b[0m\n\u001b[1;32m   1451\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mDataTypes for all columns should be the same\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1452\u001b[0m     \u001b[39mreturn\u001b[39;00m rdf\u001b[39m.\u001b[39mcollect()\n\u001b[0;32m-> 1454\u001b[0m rdf \u001b[39m=\u001b[39m _verify_schema(rdf)\n\u001b[1;32m   1455\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner \u001b[39m=\u001b[39m rdf\u001b[39m.\u001b[39m_inner\n\u001b[1;32m   1456\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_meta: Metadata \u001b[39m=\u001b[39m rdf\u001b[39m.\u001b[39m_meta\n",
      "File \u001b[0;32m~/Projects/bastionlab/client/src/bastionlab/polars/remote_polars.py:1448\u001b[0m, in \u001b[0;36mRemoteArray.__init__.<locals>._verify_schema\u001b[0;34m(rdf)\u001b[0m\n\u001b[1;32m   1446\u001b[0m dtypes \u001b[39m=\u001b[39m rdf\u001b[39m.\u001b[39mschema\u001b[39m.\u001b[39mvalues()\n\u001b[1;32m   1447\u001b[0m \u001b[39mif\u001b[39;00m pl\u001b[39m.\u001b[39mUtf8 \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(dtypes):\n\u001b[0;32m-> 1448\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUtf8 column cannot be converted into RemoteArray\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1450\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(dtypes)) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1451\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mDataTypes for all columns should be the same\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Utf8 column cannot be converted into RemoteArray"
     ]
    }
   ],
   "source": [
    "rdf.to_array()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that we had an error when we tried to convert the `RemoteDataFrame` into a `RemoteArray`. The error message is _\"TypeError: Utf8 column cannot be converted into RemoteArray\"_.\n",
    "\n",
    "This means we need to make sure our dataframe has only numerical fields (ints,floats) before we convert into `RemoteArray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "no_execute"
    ]
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DataTypes for all columns should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m rdf \u001b[39m=\u001b[39m rdf\u001b[39m.\u001b[39mselect(pl\u001b[39m.\u001b[39mcol([pl\u001b[39m.\u001b[39mFloat64, pl\u001b[39m.\u001b[39mFloat32, pl\u001b[39m.\u001b[39mInt64, pl\u001b[39m.\u001b[39mInt32]))\n\u001b[0;32m----> 3\u001b[0m rdf\u001b[39m.\u001b[39;49mto_array()\n",
      "File \u001b[0;32m~/Projects/bastionlab/client/src/bastionlab/polars/remote_polars.py:324\u001b[0m, in \u001b[0;36mRemoteLazyFrame.to_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_array\u001b[39m(\u001b[39mself\u001b[39m: LDF) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mRemoteArray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m     \u001b[39mreturn\u001b[39;00m RemoteArray(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/Projects/bastionlab/client/src/bastionlab/polars/remote_polars.py:1454\u001b[0m, in \u001b[0;36mRemoteArray.__init__\u001b[0;34m(self, rdf)\u001b[0m\n\u001b[1;32m   1451\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mDataTypes for all columns should be the same\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1452\u001b[0m     \u001b[39mreturn\u001b[39;00m rdf\u001b[39m.\u001b[39mcollect()\n\u001b[0;32m-> 1454\u001b[0m rdf \u001b[39m=\u001b[39m _verify_schema(rdf)\n\u001b[1;32m   1455\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner \u001b[39m=\u001b[39m rdf\u001b[39m.\u001b[39m_inner\n\u001b[1;32m   1456\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_meta: Metadata \u001b[39m=\u001b[39m rdf\u001b[39m.\u001b[39m_meta\n",
      "File \u001b[0;32m~/Projects/bastionlab/client/src/bastionlab/polars/remote_polars.py:1451\u001b[0m, in \u001b[0;36mRemoteArray.__init__.<locals>._verify_schema\u001b[0;34m(rdf)\u001b[0m\n\u001b[1;32m   1448\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUtf8 column cannot be converted into RemoteArray\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1450\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(dtypes)) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 1451\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mDataTypes for all columns should be the same\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1452\u001b[0m \u001b[39mreturn\u001b[39;00m rdf\u001b[39m.\u001b[39mcollect()\n",
      "\u001b[0;31mTypeError\u001b[0m: DataTypes for all columns should be the same"
     ]
    }
   ],
   "source": [
    "rdf = rdf.select(pl.col([pl.Float64, pl.Float32, pl.Int64, pl.Int32]))\n",
    "\n",
    "rdf.to_array()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, our `to_array` method gives out an error, and this time it says that _\"DataTypes for all columns should be the same\"_.\n",
    "\n",
    "This means we need to cast all our columns first before converting into an array.\n",
    "\n",
    "And, we choose to cast our columns to `Float64` to capture all numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = rdf.select(pl.all().cast(pl.Float64))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then finally, we can successfully convert our `RemoteDataFrame` into `RemoteArray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RemoteArray(identifier=091d9529-2369-45b2-bc2b-151ab9eb5eb5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf.to_array()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see right above that our `RemoteDataFrame` has been converted into a `RemoteArray`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert RemoteArrays to RemoteTensors\n",
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for us to train on our amazing deepl learning and machine learning models on `RemoteDataFrame`s, they would have to converted into `RemoteTensor`s.\n",
    "\n",
    "The section right above demonstates how to convert a `RemoteDataFrame` into `RemoteArray`.\n",
    "\n",
    "In this section, we further that illustration by converting a `RemoteArray` into a `RemoteTensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts `RemoteArray` into `RemoteTensor`\n",
    "remote_tensor = rdf.to_array().to_tensor()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the `RemoteTensor` has been created, we can go ahead and print the available properties, which are `dtype` and `shape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RemoteTensor(identifier=67094d5d-2be3-4ef6-bec6-64e83827d0cb, dtype=torch.float64, shape=torch.Size([100, 7]))\n"
     ]
    }
   ],
   "source": [
    "print(remote_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `RemoteTensor` limits the access to the tensor stored on the server by only providing you with a single API to update the `dtype` of the corresponding `Tensor` stored on the server."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating the `dtype` of our `RemoteTensor`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import torch and call the `to` method provided on the `RemoteTensor` to update the `dtype` of the `RemoteTensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RemoteTensor(identifier=67094d5d-2be3-4ef6-bec6-64e83827d0cb, dtype=torch.int64, shape=torch.Size([100, 7]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "remote_tensor.to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(remote_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the print message above, we can observe that the `dtype` for the RemoteTensor has been updated to `int64`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OrZA7dZnKido"
   },
   "source": [
    "Let's now close the connection and shutdown the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.close()\n",
    "bastionlab_server.stop(srv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cfb725626286d8c8fc5334ffe77697f720dc23e64d3046271825a5556b528e7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
