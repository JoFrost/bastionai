{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/kbamponsem/base/lib/python3.8/site-packages (1.12.0+cpu)\n",
      "Requirement already satisfied: typing-extensions in /home/kbamponsem/base/lib/python3.8/site-packages (from torch) (4.2.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from bastionai.client import connect\n",
    "from bastionai.pb.remote_torch_pb2 import TestConfig, TrainConfig\n",
    "from bastionai.psg.nn import Linear\n",
    "from torch import Tensor\n",
    "from torch.nn import Module\n",
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a simple neural network that simply employs a Linear layer to perform linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LReg(Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.fc1 = Linear(1, 1, 2)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.fc1(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple dataloader described below serving two tensors both holding 4 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRegDataset(Dataset):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.X = torch.tensor([[0.0], [1.0], [0.5], [0.2]])\n",
    "        self.Y = torch.tensor([[0.0], [2.0], [1.0], [0.4]])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return 4\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        return (self.X[idx], self.Y[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializes both the model and the dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg_model = LReg()\n",
    "lreg_dataset = LRegDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once BastionAI receives artifacts (both datasets and models,) it returns references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ref: identifier: \"57bae2ed-bd2a-495e-8321-c0dbd43220db\"\n",
      "description: \"1D Linear Regression Model\"\n",
      "\n",
      "Dataset ref: identifier: \"9af94af1-296f-4360-86e2-e2095e3ba532\"\n",
      "description: \"Dummy 1D Linear Regression Dataset (param is 2)\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "client = connect(addr=\"localhost\", port=50053)\n",
    "\n",
    "model_ref = client.send_model(\n",
    "    lreg_model, \"1D Linear Regression Model\", b\"secret\")\n",
    "print(f\"Model ref: {model_ref}\")\n",
    "\n",
    "dataset_ref = client.send_dataset(\n",
    "    lreg_dataset, \"Dummy 1D Linear Regression Dataset (param is 2)\", b'secret')\n",
    "print(f\"Dataset ref: {dataset_ref}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we fetch all the available models and datasets on BastionAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list {\n",
      "  identifier: \"57bae2ed-bd2a-495e-8321-c0dbd43220db\"\n",
      "  description: \"1D Linear Regression Model\"\n",
      "}\n",
      "\n",
      "list {\n",
      "  identifier: \"9af94af1-296f-4360-86e2-e2095e3ba532\"\n",
      "  description: \"Dummy 1D Linear Regression Dataset (param is 2)\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "client = connect(\"localhost\", 50053)\n",
    "available_models = client.get_available_models()\n",
    "print(available_models)\n",
    "\n",
    "available_datasets = client.get_available_datasets()\n",
    "print(available_datasets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models on BastionAI can be either trained on GPU or CPU. Below, we use the `get_devices` endpoint to see the available devices on BastionAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cpu']\n"
     ]
    }
   ],
   "source": [
    "client = connect(\"localhost\", 50053)\n",
    "\n",
    "available_devices = client.get_available_devices()\n",
    "print(available_devices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the power of BastionAI, we train the simple Linear regression neural network defined above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bastionai.utils.utils import create_training_config, Optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 810.18batch/s, loss (l2)=0.9107] \n",
      "Epoch 2/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 821.85batch/s, loss (l2)=0.7976] \n",
      "Epoch 3/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 506.22batch/s, loss (l2)=0.6787]\n",
      "Epoch 4/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 806.52batch/s, loss (l2)=0.5725]\n",
      "Epoch 5/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 538.49batch/s, loss (l2)=0.4833]\n",
      "Epoch 6/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 289.77batch/s, loss (l2)=0.4278]\n",
      "Epoch 7/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 764.55batch/s, loss (l2)=0.3819] \n",
      "Epoch 8/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 452.90batch/s, loss (l2)=0.3442]\n",
      "Epoch 9/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 673.30batch/s, loss (l2)=0.3179] \n",
      "Epoch 10/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 142.62batch/s, loss (l2)=0.3371]\n",
      "Epoch 11/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 584.16batch/s, loss (l2)=0.3313]\n",
      "Epoch 12/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 553.01batch/s, loss (l2)=0.2885]\n",
      "Epoch 13/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 392.80batch/s, loss (l2)=0.3060]\n",
      "Epoch 14/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 668.41batch/s, loss (l2)=0.2965]\n",
      "Epoch 15/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 458.29batch/s, loss (l2)=0.2843]\n",
      "Epoch 16/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 605.85batch/s, loss (l2)=0.2425]\n",
      "Epoch 17/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 801.13batch/s, loss (l2)=0.2317] \n",
      "Epoch 18/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 455.26batch/s, loss (l2)=0.2215]\n",
      "Epoch 19/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 612.71batch/s, loss (l2)=0.2454]\n",
      "Epoch 20/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 444.81batch/s, loss (l2)=0.2027]\n",
      "Epoch 21/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 522.59batch/s, loss (l2)=0.1920]\n",
      "Epoch 22/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 382.95batch/s, loss (l2)=0.2035]\n",
      "Epoch 23/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 411.47batch/s, loss (l2)=0.1996]\n",
      "Epoch 24/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 365.80batch/s, loss (l2)=0.1564]\n",
      "Epoch 25/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 555.50batch/s, loss (l2)=0.1777]\n",
      "Epoch 26/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 306.11batch/s, loss (l2)=0.1445]\n",
      "Epoch 27/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 563.11batch/s, loss (l2)=0.1608]\n",
      "Epoch 28/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 453.83batch/s, loss (l2)=0.1177]\n",
      "Epoch 29/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 594.35batch/s, loss (l2)=0.1100]\n",
      "Epoch 30/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 642.41batch/s, loss (l2)=0.1041]\n",
      "Epoch 31/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 483.08batch/s, loss (l2)=0.0946]\n",
      "Epoch 32/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 427.84batch/s, loss (l2)=0.0816]\n",
      "Epoch 33/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 686.75batch/s, loss (l2)=0.0994]\n",
      "Epoch 34/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 505.16batch/s, loss (l2)=0.0801]\n",
      "Epoch 35/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 408.13batch/s, loss (l2)=0.0912]\n",
      "Epoch 36/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 758.94batch/s, loss (l2)=0.0521] \n",
      "Epoch 37/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 488.79batch/s, loss (l2)=0.0463]\n",
      "Epoch 38/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 663.39batch/s, loss (l2)=0.0649]\n",
      "Epoch 39/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 430.60batch/s, loss (l2)=0.0385]\n",
      "Epoch 40/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 726.73batch/s, loss (l2)=0.0333]\n",
      "Epoch 41/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 505.79batch/s, loss (l2)=0.0284]\n",
      "Epoch 42/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 638.26batch/s, loss (l2)=0.0363]\n",
      "Epoch 43/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 719.99batch/s, loss (l2)=0.0268]\n",
      "Epoch 44/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 450.64batch/s, loss (l2)=0.0323]\n",
      "Epoch 45/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 503.76batch/s, loss (l2)=0.0072]\n",
      "Epoch 46/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 566.72batch/s, loss (l2)=0.0275]\n",
      "Epoch 47/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 621.79batch/s, loss (l2)=0.0351]\n",
      "Epoch 48/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 353.46batch/s, loss (l2)=0.0122]\n",
      "Epoch 49/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 697.48batch/s, loss (l2)=0.0285]\n",
      "Epoch 50/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 751.26batch/s, loss (l2)=0.0321]\n",
      "Epoch 51/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 402.56batch/s, loss (l2)=0.0269]\n",
      "Epoch 52/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 590.75batch/s, loss (l2)=0.0323]\n",
      "Epoch 53/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 162.68batch/s, loss (l2)=0.0309]\n",
      "Epoch 54/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 447.66batch/s, loss (l2)=0.0265]\n",
      "Epoch 55/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 533.90batch/s, loss (l2)=0.0225]\n",
      "Epoch 56/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 360.37batch/s, loss (l2)=0.0305]\n",
      "Epoch 57/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 480.14batch/s, loss (l2)=0.0319]\n",
      "Epoch 58/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 366.20batch/s, loss (l2)=0.0321]\n",
      "Epoch 59/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 613.20batch/s, loss (l2)=0.0308]\n",
      "Epoch 60/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 443.28batch/s, loss (l2)=0.0232]\n",
      "Epoch 61/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 697.02batch/s, loss (l2)=0.0268]\n",
      "Epoch 62/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 550.76batch/s, loss (l2)=0.0270]\n",
      "Epoch 63/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 568.41batch/s, loss (l2)=0.0218]\n",
      "Epoch 64/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 454.10batch/s, loss (l2)=0.0507]\n",
      "Epoch 65/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 569.80batch/s, loss (l2)=0.0294]\n",
      "Epoch 66/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 756.28batch/s, loss (l2)=0.0346]\n",
      "Epoch 67/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 612.66batch/s, loss (l2)=0.0224]\n",
      "Epoch 68/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 396.14batch/s, loss (l2)=0.0273]\n",
      "Epoch 69/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 492.26batch/s, loss (l2)=0.0324]\n",
      "Epoch 70/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 443.16batch/s, loss (l2)=0.0417]\n",
      "Epoch 71/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 624.15batch/s, loss (l2)=0.0272]\n",
      "Epoch 72/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 452.24batch/s, loss (l2)=0.0333]\n",
      "Epoch 73/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 399.55batch/s, loss (l2)=0.0255]\n",
      "Epoch 74/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 527.95batch/s, loss (l2)=0.0232]\n",
      "Epoch 75/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 629.44batch/s, loss (l2)=0.0305]\n",
      "Epoch 76/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 669.43batch/s, loss (l2)=0.0344]\n",
      "Epoch 77/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 421.71batch/s, loss (l2)=0.0301]\n",
      "Epoch 78/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 640.74batch/s, loss (l2)=0.0310]\n",
      "Epoch 79/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 352.33batch/s, loss (l2)=0.0284]\n",
      "Epoch 80/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 641.63batch/s, loss (l2)=0.0344]\n",
      "Epoch 81/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 761.49batch/s, loss (l2)=0.0278] \n",
      "Epoch 82/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 592.71batch/s, loss (l2)=0.0258]\n",
      "Epoch 83/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 537.52batch/s, loss (l2)=0.0270]\n",
      "Epoch 84/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 679.35batch/s, loss (l2)=0.0346]\n",
      "Epoch 85/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 674.38batch/s, loss (l2)=0.0243]\n",
      "Epoch 86/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 409.50batch/s, loss (l2)=0.0433]\n",
      "Epoch 87/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 615.41batch/s, loss (l2)=0.0261]\n",
      "Epoch 88/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 630.58batch/s, loss (l2)=0.0306]\n",
      "Epoch 89/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 697.71batch/s, loss (l2)=0.0332]\n",
      "Epoch 90/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 586.78batch/s, loss (l2)=0.0263]\n",
      "Epoch 91/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 517.21batch/s, loss (l2)=0.0380]\n",
      "Epoch 92/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 490.88batch/s, loss (l2)=0.0307]\n",
      "Epoch 93/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 222.87batch/s, loss (l2)=0.0312]\n",
      "Epoch 94/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 594.18batch/s, loss (l2)=0.0309]\n",
      "Epoch 95/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 217.77batch/s, loss (l2)=0.0275]\n",
      "Epoch 96/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 445.21batch/s, loss (l2)=0.0292]\n",
      "Epoch 97/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 395.93batch/s, loss (l2)=0.0338]\n",
      "Epoch 98/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 598.97batch/s, loss (l2)=0.0263]\n",
      "Epoch 99/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 671.25batch/s, loss (l2)=0.0267]\n",
      "Epoch 100/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 659.43batch/s, loss (l2)=0.0236] \n"
     ]
    }
   ],
   "source": [
    "client = connect(addr=\"localhost\", port=50053)\n",
    "training_config = create_training_config(model_ref,\n",
    "                                         dataset_ref,\n",
    "                                         batch_size=2,\n",
    "                                         epochs=100,\n",
    "                                         learning_rate=0.1,\n",
    "                                         weight_decay=0.,\n",
    "                                         noise_multiplier=0.1,\n",
    "                                         max_grad_norm=1.,\n",
    "                                         extra_args={\n",
    "                                             \"momentum\": 0.,\n",
    "                                             \"dampening\": 0.,\n",
    "                                             \"nesterov\": False\n",
    "                                         },\n",
    "                                         optimizer=Optimizers.SGD)\n",
    "\n",
    "client.train(training_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We securely fetch the trained weights from BastionAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = connect(\"localhost\", 50051)\n",
    "client.fetch_model_weights(lreg_model, model_ref)\n",
    "print(f\"Weight: {lreg_model.fc1.inner.expanded_weight}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cfb725626286d8c8fc5334ffe77697f720dc23e64d3046271825a5556b528e7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
