{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/kbamponsem/base/lib/python3.8/site-packages (1.12.0+cpu)\n",
      "Requirement already satisfied: typing-extensions in /home/kbamponsem/base/lib/python3.8/site-packages (from torch) (4.2.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from bastionai.client import Connection\n",
    "from bastionai.pb.remote_torch_pb2 import TestConfig, TrainConfig\n",
    "from bastionai.psg.nn import Linear\n",
    "from torch import Tensor\n",
    "from torch.nn import Module\n",
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a simple neural network that simply employs a Linear layer to perform linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LReg(Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.fc1 = Linear(1, 1, 2)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.fc1(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple dataloader described below serving two tensors both holding 4 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRegDataset(Dataset):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.X = torch.tensor([[0.0], [1.0], [0.5], [0.2]])\n",
    "        self.Y = torch.tensor([[0.0], [2.0], [1.0], [0.4]])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return 4\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        return (self.X[idx], self.Y[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializes both the model and the dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg_model = LReg()\n",
    "lreg_dataset = LRegDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once BastionAI receives artifacts (both datasets and models,) it returns references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ref: identifier: \"27a9cac1-8eae-44f1-b12e-672126030151\"\n",
      "description: \"1D Linear Regression Model\"\n",
      "\n",
      "Dataset ref: identifier: \"fde62f6e-738f-4df7-8c14-4ca5de69b83c\"\n",
      "description: \"Dummy 1D Linear Regression Dataset (param is 2)\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with Connection(\"localhost\", 50051) as client:\n",
    "    model_ref = client.send_model(\n",
    "        lreg_model, \"1D Linear Regression Model\", b\"secret\")\n",
    "    print(f\"Model ref: {model_ref}\")\n",
    "\n",
    "    dataset_ref = client.send_dataset(\n",
    "        lreg_dataset, \"Dummy 1D Linear Regression Dataset (param is 2)\", b'secret')\n",
    "    print(f\"Dataset ref: {dataset_ref}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we fetch all the available models and datasets on BastionAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list {\n",
      "  identifier: \"27a9cac1-8eae-44f1-b12e-672126030151\"\n",
      "  description: \"1D Linear Regression Model\"\n",
      "}\n",
      "\n",
      "list {\n",
      "  identifier: \"fde62f6e-738f-4df7-8c14-4ca5de69b83c\"\n",
      "  description: \"Dummy 1D Linear Regression Dataset (param is 2)\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with Connection(\"localhost\", 50051) as client:\n",
    "    available_models = client.get_available_models()\n",
    "    print(available_models)\n",
    "\n",
    "    available_datasets = client.get_available_datasets()\n",
    "    print(available_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models on BastionAI can be either trained on GPU or CPU. Below, we use the `get_devices` endpoint to see the available devices on BastionAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list: \"cpu\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with Connection(\"localhost\", 50051) as client:\n",
    "    available_devices = client.get_available_devices()\n",
    "    print(available_devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the power of BastionAI, we train the simple Linear regression neural network defined above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bastionai.utils import create_training_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 645.77batch/s, loss (l2)=0.0037] \n",
      "Epoch 2/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 301.55batch/s, loss (l2)=0.0037]\n",
      "Epoch 3/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 500.84batch/s, loss (l2)=0.0037]\n",
      "Epoch 4/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 464.77batch/s, loss (l2)=0.0037]\n",
      "Epoch 5/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 251.68batch/s, loss (l2)=0.0037]\n",
      "Epoch 6/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 550.33batch/s, loss (l2)=0.0037]\n",
      "Epoch 7/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 178.07batch/s, loss (l2)=0.0037]\n",
      "Epoch 8/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 261.25batch/s, loss (l2)=0.0037]\n",
      "Epoch 9/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 522.10batch/s, loss (l2)=0.0037]\n",
      "Epoch 10/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 449.82batch/s, loss (l2)=0.0037]\n",
      "Epoch 11/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 524.94batch/s, loss (l2)=0.0037]\n",
      "Epoch 12/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 457.84batch/s, loss (l2)=0.0037]\n",
      "Epoch 13/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 426.16batch/s, loss (l2)=0.0037]\n",
      "Epoch 14/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 442.86batch/s, loss (l2)=0.0037]\n",
      "Epoch 15/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 284.15batch/s, loss (l2)=0.0037]\n",
      "Epoch 16/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 532.91batch/s, loss (l2)=0.0037]\n",
      "Epoch 17/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 444.74batch/s, loss (l2)=0.0037]\n",
      "Epoch 18/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 467.12batch/s, loss (l2)=0.0037]\n",
      "Epoch 19/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 425.93batch/s, loss (l2)=0.0037]\n",
      "Epoch 20/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 591.21batch/s, loss (l2)=0.0037]\n",
      "Epoch 21/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 563.45batch/s, loss (l2)=0.0037]\n",
      "Epoch 22/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 485.82batch/s, loss (l2)=0.0037]\n",
      "Epoch 23/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 750.99batch/s, loss (l2)=0.0037]\n",
      "Epoch 24/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 386.50batch/s, loss (l2)=0.0037]\n",
      "Epoch 25/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 598.16batch/s, loss (l2)=0.0037]\n",
      "Epoch 26/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 260.81batch/s, loss (l2)=0.0037]\n",
      "Epoch 27/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 608.40batch/s, loss (l2)=0.0037]\n",
      "Epoch 28/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 380.99batch/s, loss (l2)=0.0037]\n",
      "Epoch 29/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 547.06batch/s, loss (l2)=0.0037]\n",
      "Epoch 30/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 395.89batch/s, loss (l2)=0.0037]\n",
      "Epoch 31/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 506.41batch/s, loss (l2)=0.0037]\n",
      "Epoch 32/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 468.40batch/s, loss (l2)=0.0037]\n",
      "Epoch 33/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 549.75batch/s, loss (l2)=0.0037]\n",
      "Epoch 34/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 610.66batch/s, loss (l2)=0.0037]\n",
      "Epoch 35/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 467.49batch/s, loss (l2)=0.0037]\n",
      "Epoch 36/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 543.20batch/s, loss (l2)=0.0037]\n",
      "Epoch 37/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 413.05batch/s, loss (l2)=0.0037]\n",
      "Epoch 38/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 626.25batch/s, loss (l2)=0.0037]\n",
      "Epoch 39/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 388.20batch/s, loss (l2)=0.0037]\n",
      "Epoch 40/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 379.01batch/s, loss (l2)=0.0037]\n",
      "Epoch 41/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 407.49batch/s, loss (l2)=0.0037]\n",
      "Epoch 42/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 431.34batch/s, loss (l2)=0.0037]\n",
      "Epoch 43/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 459.90batch/s, loss (l2)=0.0037]\n",
      "Epoch 44/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 343.20batch/s, loss (l2)=0.0037]\n",
      "Epoch 45/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 460.94batch/s, loss (l2)=0.0037]\n",
      "Epoch 46/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 383.46batch/s, loss (l2)=0.0037]\n",
      "Epoch 47/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 437.73batch/s, loss (l2)=0.0037]\n",
      "Epoch 48/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 496.10batch/s, loss (l2)=0.0037]\n",
      "Epoch 49/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 517.14batch/s, loss (l2)=0.0037]\n",
      "Epoch 50/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 325.29batch/s, loss (l2)=0.0037]\n",
      "Epoch 51/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 502.97batch/s, loss (l2)=0.0037]\n",
      "Epoch 52/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 518.68batch/s, loss (l2)=0.0037]\n",
      "Epoch 53/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 492.72batch/s, loss (l2)=0.0037]\n",
      "Epoch 54/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 377.83batch/s, loss (l2)=0.0037]\n",
      "Epoch 55/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 524.71batch/s, loss (l2)=0.0037]\n",
      "Epoch 56/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 336.66batch/s, loss (l2)=0.0037]\n",
      "Epoch 57/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 565.73batch/s, loss (l2)=0.0037]\n",
      "Epoch 58/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 378.72batch/s, loss (l2)=0.0037]\n",
      "Epoch 59/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 449.29batch/s, loss (l2)=0.0037]\n",
      "Epoch 60/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 391.48batch/s, loss (l2)=0.0037]\n",
      "Epoch 61/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 561.04batch/s, loss (l2)=0.0037]\n",
      "Epoch 62/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 325.83batch/s, loss (l2)=0.0037]\n",
      "Epoch 63/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 495.31batch/s, loss (l2)=0.0037]\n",
      "Epoch 64/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 437.48batch/s, loss (l2)=0.0037]\n",
      "Epoch 65/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 336.95batch/s, loss (l2)=0.0037]\n",
      "Epoch 66/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 426.16batch/s, loss (l2)=0.0037]\n",
      "Epoch 67/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 321.86batch/s, loss (l2)=0.0037]\n",
      "Epoch 68/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 532.64batch/s, loss (l2)=0.0037]\n",
      "Epoch 69/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 377.39batch/s, loss (l2)=0.0037]\n",
      "Epoch 70/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 668.41batch/s, loss (l2)=0.0037]\n",
      "Epoch 71/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 525.37batch/s, loss (l2)=0.0037]\n",
      "Epoch 72/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 294.25batch/s, loss (l2)=0.0037]\n",
      "Epoch 73/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 643.59batch/s, loss (l2)=0.0037]\n",
      "Epoch 74/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 204.09batch/s, loss (l2)=0.0037]\n",
      "Epoch 75/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 399.57batch/s, loss (l2)=0.0037]\n",
      "Epoch 76/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 538.77batch/s, loss (l2)=0.0037]\n",
      "Epoch 77/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 664.02batch/s, loss (l2)=0.0037]\n",
      "Epoch 78/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 361.67batch/s, loss (l2)=0.0037]\n",
      "Epoch 79/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 567.41batch/s, loss (l2)=0.0037]\n",
      "Epoch 80/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 336.76batch/s, loss (l2)=0.0037]\n",
      "Epoch 81/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 495.49batch/s, loss (l2)=0.0037]\n",
      "Epoch 82/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 387.95batch/s, loss (l2)=0.0037]\n",
      "Epoch 83/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 571.66batch/s, loss (l2)=0.0037]\n",
      "Epoch 84/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 440.09batch/s, loss (l2)=0.0037]\n",
      "Epoch 85/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 127.43batch/s, loss (l2)=0.0037]\n",
      "Epoch 86/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 148.57batch/s, loss (l2)=0.0037]\n",
      "Epoch 87/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 404.48batch/s, loss (l2)=0.0037]\n",
      "Epoch 88/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 496.78batch/s, loss (l2)=0.0037]\n",
      "Epoch 89/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 514.17batch/s, loss (l2)=0.0037]\n",
      "Epoch 90/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 462.59batch/s, loss (l2)=0.0037]\n",
      "Epoch 91/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 617.85batch/s, loss (l2)=0.0037]\n",
      "Epoch 92/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 403.34batch/s, loss (l2)=0.0037]\n",
      "Epoch 93/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 308.50batch/s, loss (l2)=0.0037]\n",
      "Epoch 94/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 473.42batch/s, loss (l2)=0.0037]\n",
      "Epoch 95/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 510.10batch/s, loss (l2)=0.0037]\n",
      "Epoch 96/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 557.01batch/s, loss (l2)=0.0037]\n",
      "Epoch 97/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 407.41batch/s, loss (l2)=0.0037]\n",
      "Epoch 98/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 660.10batch/s, loss (l2)=0.0037]\n",
      "Epoch 99/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 538.32batch/s, loss (l2)=0.0037]\n",
      "Epoch 100/100 - train: 100%|████████████████████| 2/2 [00:00<00:00, 491.40batch/s, loss (l2)=0.0037]\n"
     ]
    }
   ],
   "source": [
    "with Connection(\"localhost\", 50051) as client:\n",
    "    training_config = create_training_config(model_ref,\n",
    "                               dataset_ref,\n",
    "                               batch_size=2,\n",
    "                               epochs=100,\n",
    "                               learning_rate=0.1,\n",
    "                               weight_decay=0.,\n",
    "                               noise_multiplier=0.1,\n",
    "                               max_grad_norm=1.,\n",
    "                               extra_args={\n",
    "                                   \"momentum\": 0.,\n",
    "                                   \"dampening\": 0.,\n",
    "                                   \"nesterov\": False\n",
    "                               },\n",
    "                               optimizer_type=\"SGD\")\n",
    "\n",
    "    client.train(training_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We securely fetch the trained weights from BastionAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Connection(\"localhost\", 50051) as client:\n",
    "    client.fetch_model_weights(lreg_model, model_ref)\n",
    "    print(f\"Weight: {lreg_model.fc1.inner.expanded_weight}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cfb725626286d8c8fc5334ffe77697f720dc23e64d3046271825a5556b528e7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
