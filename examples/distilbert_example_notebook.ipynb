{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bastion AI Real World Example\n",
    "## Finetuning DistilBERT for binary classification on the SMS Spam Collection\n",
    "\n",
    "Data preparation and training are largely based on https://towardsdatascience.com/fine-tuning-bert-for-text-classification-54e7df642894.\n",
    "\n",
    "### Installing Bastion AI\n",
    "\n",
    "### From source\n",
    "\n",
    "To use this notebook, you'll need a working Bastion AI installation.\n",
    "First clone our repo:\n",
    "```\n",
    "$ git clone git@github.com:mithril-security/bastionai.git\n",
    "```\n",
    "Then install the client library:\n",
    "```\n",
    "$ cd ./bastionai/client\n",
    "$ make install\n",
    "```\n",
    "\n",
    "### Via pip\n",
    "\n",
    "Just run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install bastionai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing and importing additionnal packages\n",
    "\n",
    "Let's first import all the necessary packages for the entire notebook.\n",
    "The makefile for the client has already set up a virtualenv with the client dependences for us.\n",
    "We just need to install the additionnal packages we'll use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers pandas sklearn ipykernel ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now import necessary packages and objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from bastionai.client import Connection\n",
    "from bastionai.optimizer_config import Adam\n",
    "from bastionai.utils import MultipleOutputWrapper, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the dataset\n",
    "\n",
    "The dataset can be found at https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip.\n",
    "Unzip the archive to obtain the datset file:\n",
    "\n",
    "```\n",
    "$ unzip smsspamcollection.zip\n",
    "```\n",
    "\n",
    "Each row represent a sample, the label come first followed by a tab and the raw text:\n",
    "```\n",
    "ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
    "ham\tOk lar... Joking wif u oni...\n",
    "spam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
    "```\n",
    "\n",
    "We first load the data from the file into a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5574\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                    Ok lar... Joking wif u oni...\\n\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"./data/SMSSpamCollection\"\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "with open(file_path) as f:\n",
    "  for line in f.readlines():\n",
    "    split = line.split('\\t')\n",
    "    labels.append(1 if split[0] == \"spam\" else 0)\n",
    "    texts.append(split[1])\n",
    "df = pd.DataFrame({ \"label\": labels, \"text\": texts })\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then preprocess the data using DistilBERT's tokenizer and we obtain tensors ready to be fed to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "token_id = []\n",
    "attention_masks = []\n",
    "for sample in df.text.values:\n",
    "    encoding_dict = tokenizer.encode_plus(\n",
    "        sample,\n",
    "        add_special_tokens=True,\n",
    "        max_length=32,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    token_id.append(encoding_dict['input_ids']) \n",
    "    attention_masks.append(encoding_dict['attention_mask'])\n",
    "\n",
    "token_id = torch.cat(token_id, dim=0).to(dtype=torch.int64)\n",
    "attention_masks = torch.cat(attention_masks, dim=0).to(dtype=torch.int64)\n",
    "labels = torch.tensor(df.label.values, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's now time to split the data in a train and test sets and to wrap it inside Dataset and DataLoader objects for ease of use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ratio = 0.2\n",
    "\n",
    "train_idx, test_idx = train_test_split(\n",
    "    np.arange(len(labels)),\n",
    "    test_size=val_ratio,\n",
    "    shuffle=True,\n",
    "    stratify=labels\n",
    ")\n",
    "\n",
    "train_set = TensorDataset([\n",
    "    token_id[train_idx], \n",
    "    attention_masks[train_idx]\n",
    "], labels[train_idx])\n",
    "\n",
    "test_set = TensorDataset([\n",
    "    token_id[test_idx], \n",
    "    attention_masks[test_idx]\n",
    "], labels[test_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the model for use with DP-SGD and Bastion AI\n",
    "\n",
    "We now turn to preparing the DistilBERT language model. As Hugging Face's models typically have several outputs (logits, loss, etc.) we use Bastion AI's utility wrapper for models with multiple outputs to select the sole output that corresponds with the logits. In fact, Bastion AI's server supports models with an arbitrtary number of inputs but only supports models with a single output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not display warnings about layer not initialized\n",
    "# with pretrained weights (classification layers, this is fine)\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased',\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    "    torchscript=True\n",
    ")\n",
    "model = MultipleOutputWrapper(model, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sending dataset and model and training on the server\n",
    "\n",
    "Before proceeding, we need to start a local Bastion AI server which can be achivied with the following commands,\n",
    "assuming you have a working rust toolchain (https://www.rust-lang.org/tools/install):\n",
    "\n",
    "```\n",
    "$ cd ../server/bastionai_app\n",
    "$ cargo run\n",
    "```\n",
    "\n",
    "Now that the server code has been compiled and the server has started, it's time to send the dataset and the model to the server.\n",
    "\n",
    "On the Data Owner side, we use the `RemoteDataset` method to send our train and test datasets to the server and we provide a name and description to better identify them. We also set a privacy limit (in terms of differential privacy budget)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Data Owner privately uploads their model online\n",
    "with Connection(\"localhost\", 50051) as client:\n",
    "    remote_dataset = client.RemoteDataset(\n",
    "        train_set, test_set,\n",
    "        name=\"SMSSpamCollection\",\n",
    "        privacy_limit=1_000_000.0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the Data Scientist side, we use the `list_remote_datasets` endpoint to get a list of available datasets on the server that we can use for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SMSSpamCollection (9a365419-4978-4ac3-aa4d-ae6ea5abd6a6): size=4459, desc=N/A']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with Connection(\"localhost\", 50051) as client:\n",
    "    remote_datasets = client.list_remote_datasets()\n",
    "\n",
    "[str(ds) for ds in remote_datasets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use the `RemoteLearner` method to send the model to the server and to set all the necessary training config.\n",
    "As training will be executed remotely, we need to script the model prior to sending it (i.e. compile it to Torch Script) which is automatically done in the `RemoteLearner` constructor. In case the model is not suited for scripting, which is generally the case with Hugging Face's models, the constructor automatically resorts to use tracing, which means the model is run locally on a small but representative input and the torch jit compiler tracks all functions that are called and compiles them on the fly. This approach, although more error prone (in certain cases the input may not activate some needed computation paths) is less picky that scripting and accepts nearly all models.\n",
    "\n",
    "In addition, as we'll use the DP-SGD algorithm for training, the constructor will also make the model compatible with Bastion AI's DP-SGD implementation. Unlike Opacus that uses backprop hooks to compute per-sample gradients, Bastion AI relies on normal autograd and modified layers that internally store expanded gradients (weight tensors have the same size in memory but are manipulated through expanded views that repeat them as many times as there are samples in a batch so that the gradient of these views are per-sample gradients). Per-samples gradient computation is key to DP-SGD and is one ingredient that make DP usable with Deep Learning models.\n",
    "\n",
    "To start training, we just call the `fit` method on the `RemoteLerner` object with appropriate number of epochs and DP budget. We can optionally override some of the learner's settings such as the learning rate or the clipping factor.\n",
    "\n",
    "We may finally retrieve a local copy of the trained model once the training is complete with the `get_model` method and test the model directly on the server with the `test` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 - train:   0%|                    | 4/1114 [00:08<37:09,  2.01s/batch, cross_entropy=10.0000 (+/- 4671.9775)] "
     ]
    },
    {
     "ename": "_InactiveRpcError",
     "evalue": "<_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"Socket closed\"\n\tdebug_error_string = \"{\"created\":\"@1662388048.812780370\",\"description\":\"Error received from peer ipv4:127.0.0.1:50051\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":966,\"grpc_message\":\"Socket closed\",\"grpc_status\":14}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/dhalf/Documents/bastionai/examples/distilbert_example_notebook.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/examples/distilbert_example_notebook.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mwith\u001b[39;00m Connection(\u001b[39m\"\u001b[39m\u001b[39mlocalhost\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m50051\u001b[39m) \u001b[39mas\u001b[39;00m client:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/examples/distilbert_example_notebook.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     remote_learner \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mRemoteLearner(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/examples/distilbert_example_notebook.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         model,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/examples/distilbert_example_notebook.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         remote_datasets[\u001b[39m0\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/examples/distilbert_example_notebook.ipynb#X23sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         model_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDistilBERT\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/examples/distilbert_example_notebook.ipynb#X23sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/examples/distilbert_example_notebook.ipynb#X23sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     remote_learner\u001b[39m.\u001b[39;49mfit(nb_epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, eps\u001b[39m=\u001b[39;49m\u001b[39m6.0\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/examples/distilbert_example_notebook.ipynb#X23sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     remote_learner\u001b[39m.\u001b[39mtest(metric\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/examples/distilbert_example_notebook.ipynb#X23sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     trained_model \u001b[39m=\u001b[39m remote_learner\u001b[39m.\u001b[39mget_model()\n",
      "File \u001b[0;32m~/Documents/bastionai/client/bastionai/learner.py:362\u001b[0m, in \u001b[0;36mRemoteLearner.fit\u001b[0;34m(self, nb_epochs, eps, batch_size, max_grad_norm, lr, metric_eps, timeout, poll_delay)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[39m\"\"\"Fits the uploaded model to the training dataset with given hyperparameters.\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \n\u001b[1;32m    346\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[39m    poll_delay: Delay in seconds between two polling requests for the loss.\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    357\u001b[0m run \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mtrain(\n\u001b[1;32m    358\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_config(\n\u001b[1;32m    359\u001b[0m         nb_epochs, eps, batch_size, max_grad_norm, lr, metric_eps\n\u001b[1;32m    360\u001b[0m     )\n\u001b[1;32m    361\u001b[0m )\n\u001b[0;32m--> 362\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll_metric(\n\u001b[1;32m    363\u001b[0m     run,\n\u001b[1;32m    364\u001b[0m     name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss,\n\u001b[1;32m    365\u001b[0m     train\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    366\u001b[0m     timeout\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m(timeout \u001b[39m/\u001b[39;49m poll_delay),\n\u001b[1;32m    367\u001b[0m     poll_delay\u001b[39m=\u001b[39;49mpoll_delay,\n\u001b[1;32m    368\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/bastionai/client/bastionai/learner.py:299\u001b[0m, in \u001b[0;36mRemoteLearner._poll_metric\u001b[0;34m(self, run, name, train, timeout, poll_delay)\u001b[0m\n\u001b[1;32m    297\u001b[0m prev_batch \u001b[39m=\u001b[39m metric\u001b[39m.\u001b[39mbatch\n\u001b[1;32m    298\u001b[0m prev_epoch \u001b[39m=\u001b[39m metric\u001b[39m.\u001b[39mepoch\n\u001b[0;32m--> 299\u001b[0m metric \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mget_metric(run)\n\u001b[1;32m    301\u001b[0m \u001b[39m# Handle end of training\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    303\u001b[0m     metric\u001b[39m.\u001b[39mepoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39m==\u001b[39m metric\u001b[39m.\u001b[39mnb_epochs\n\u001b[1;32m    304\u001b[0m     \u001b[39mand\u001b[39;00m metric\u001b[39m.\u001b[39mbatch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39m==\u001b[39m metric\u001b[39m.\u001b[39mnb_batches\n\u001b[1;32m    305\u001b[0m ):\n",
      "File \u001b[0;32m~/Documents/bastionai/client/bastionai/client.py:205\u001b[0m, in \u001b[0;36mClient.get_metric\u001b[0;34m(self, run)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_metric\u001b[39m(\u001b[39mself\u001b[39m, run: Reference) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Metric:\n\u001b[1;32m    200\u001b[0m     \u001b[39m\"\"\"Returns the value of the metric associated with the given `run` reference.\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[39m        run: BastionAI gRPC protocol reference of the run whose metric is read.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstub\u001b[39m.\u001b[39;49mGetMetric(run)\n",
      "File \u001b[0;32m~/Documents/bastionai/client/venv/lib/python3.10/site-packages/grpc/_channel.py:946\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m    938\u001b[0m              request,\n\u001b[1;32m    939\u001b[0m              timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    942\u001b[0m              wait_for_ready\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    943\u001b[0m              compression\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    944\u001b[0m     state, call, \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blocking(request, timeout, metadata, credentials,\n\u001b[1;32m    945\u001b[0m                                   wait_for_ready, compression)\n\u001b[0;32m--> 946\u001b[0m     \u001b[39mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[39mFalse\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Documents/bastionai/client/venv/lib/python3.10/site-packages/grpc/_channel.py:849\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[39mreturn\u001b[39;00m state\u001b[39m.\u001b[39mresponse\n\u001b[1;32m    848\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 849\u001b[0m     \u001b[39mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"Socket closed\"\n\tdebug_error_string = \"{\"created\":\"@1662388048.812780370\",\"description\":\"Error received from peer ipv4:127.0.0.1:50051\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":966,\"grpc_message\":\"Socket closed\",\"grpc_status\":14}\"\n>"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# The Data Scientist discovers available datasets and use one of them to train their model\n",
    "with Connection(\"localhost\", 50051) as client:\n",
    "    remote_learner = client.RemoteLearner(\n",
    "        model,\n",
    "        remote_datasets[0],\n",
    "        max_batch_size=4,\n",
    "        loss=\"cross_entropy\",\n",
    "        optimizer=Adam(lr=5e-5),\n",
    "        model_name=\"DistilBERT\",\n",
    "    )\n",
    "\n",
    "    remote_learner.fit(nb_epochs=2, eps=6.0)\n",
    "    remote_learner.test(metric=\"accuracy\")\n",
    "    \n",
    "    trained_model = remote_learner.get_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6993cb9073eaa1097b6e3b6529d06c5840b05bad16c8a47177ac9bf16f0b1e0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
