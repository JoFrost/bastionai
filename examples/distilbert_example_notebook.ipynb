{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bastion AI Real World Example\n",
    "## Finetuning DistilBERT for binary classification on the SMS Spam Collection\n",
    "\n",
    "Data preparation and training are largely based on https://towardsdatascience.com/fine-tuning-bert-for-text-classification-54e7df642894.\n",
    "\n",
    "### Installing Bastion AI\n",
    "\n",
    "### From source\n",
    "\n",
    "To use this notebook, you'll need a working Bastion AI installation.\n",
    "First clone our repo:\n",
    "```\n",
    "$ git clone git@github.com:mithril-security/bastionai.git\n",
    "```\n",
    "Then install the client library:\n",
    "```\n",
    "$ cd ./bastionai/client\n",
    "$ make install\n",
    "```\n",
    "\n",
    "### Via pip\n",
    "\n",
    "Just run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install bastionai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing and importing additionnal packages\n",
    "\n",
    "Let's first import all the necessary packages for the entire notebook.\n",
    "The makefile for the client has already set up a virtualenv with the client dependences for us.\n",
    "We just need to install the additionnal packages we'll use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.21.1-py3-none-any.whl (4.7 MB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-1.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: ipykernel in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (6.15.1)\n",
      "Collecting ipywidgets\n",
      "  Using cached ipywidgets-7.7.1-py2.py3-none-any.whl (123 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (682 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from transformers) (4.64.0)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2022.7.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (765 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from transformers) (1.23.1)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Using cached tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.8.0-py3-none-any.whl (10 kB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Using cached huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2022.2.1-py2.py3-none-any.whl (500 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.6/500.6 KB\u001b[0m \u001b[31m686.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn\n",
      "  Using cached scikit_learn-1.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.5 MB)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from ipykernel) (7.3.4)\n",
      "Requirement already satisfied: debugpy>=1.0 in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from ipykernel) (1.6.3)\n",
      "Requirement already satisfied: nest-asyncio in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from ipykernel) (1.5.5)\n",
      "Requirement already satisfied: pyzmq>=17 in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from ipykernel) (23.2.1)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from ipykernel) (8.4.0)\n",
      "Requirement already satisfied: psutil in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from ipykernel) (5.9.1)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from ipykernel) (6.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from ipykernel) (0.1.3)\n",
      "Requirement already satisfied: traitlets>=5.1.0 in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from ipykernel) (5.3.0)\n",
      "Collecting widgetsnbextension~=3.6.0\n",
      "  Using cached widgetsnbextension-3.6.1-py2.py3-none-any.whl (1.6 MB)\n",
      "Collecting jupyterlab-widgets>=1.0.0\n",
      "  Using cached jupyterlab_widgets-1.1.1-py3-none-any.whl (245 kB)\n",
      "Collecting ipython-genutils~=0.2.0\n",
      "  Using cached ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: stack-data in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (0.4.0)\n",
      "Requirement already satisfied: decorator in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
      "Requirement already satisfied: backcall in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (0.2.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (2.13.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (0.18.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (59.6.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (3.0.30)\n",
      "Requirement already satisfied: entrypoints in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel) (0.4)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel) (4.11.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Collecting notebook>=4.4.1\n",
      "  Using cached notebook-6.4.12-py3-none-any.whl (9.9 MB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.11-py2.py3-none-any.whl (139 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting charset-normalizer<3,>=2\n",
      "  Using cached charset_normalizer-2.1.0-py3-none-any.whl (39 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2022.6.15-py3-none-any.whl (160 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting scipy>=1.3.2\n",
      "  Using cached scipy-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
      "Collecting joblib>=1.0.0\n",
      "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.3)\n",
      "Collecting terminado>=0.8.3\n",
      "  Using cached terminado-0.15.0-py3-none-any.whl (16 kB)\n",
      "Collecting nbconvert>=5\n",
      "  Using cached nbconvert-6.5.3-py3-none-any.whl (563 kB)\n",
      "Collecting argon2-cffi\n",
      "  Using cached argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n",
      "Collecting prometheus-client\n",
      "  Using cached prometheus_client-0.14.1-py3-none-any.whl (59 kB)\n",
      "Collecting jinja2\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Collecting Send2Trash>=1.8.0\n",
      "  Using cached Send2Trash-1.8.0-py3-none-any.whl (18 kB)\n",
      "Collecting nbformat\n",
      "  Using cached nbformat-5.4.0-py3-none-any.whl (73 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel) (0.2.5)\n",
      "Requirement already satisfied: pure-eval in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.2)\n",
      "Requirement already satisfied: asttokens in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.0.8)\n",
      "Requirement already satisfied: executing in /home/dhalf/Documents/bastionai/client/venv/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.10.0)\n",
      "Collecting lxml\n",
      "  Using cached lxml-4.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.9 MB)\n",
      "Collecting bleach\n",
      "  Using cached bleach-5.0.1-py3-none-any.whl (160 kB)\n",
      "Collecting mistune<2,>=0.8.1\n",
      "  Using cached mistune-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Collecting jupyterlab-pygments\n",
      "  Using cached jupyterlab_pygments-0.2.2-py2.py3-none-any.whl (21 kB)\n",
      "Collecting nbclient>=0.5.0\n",
      "  Using cached nbclient-0.6.6-py3-none-any.whl (71 kB)\n",
      "Collecting pandocfilters>=1.4.1\n",
      "  Using cached pandocfilters-1.5.0-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting tinycss2\n",
      "  Using cached tinycss2-1.1.1-py3-none-any.whl (21 kB)\n",
      "Collecting defusedxml\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
      "Collecting jsonschema>=2.6\n",
      "  Downloading jsonschema-4.10.0-py3-none-any.whl (80 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.8/80.8 KB\u001b[0m \u001b[31m966.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting fastjsonschema\n",
      "  Using cached fastjsonschema-2.16.1-py3-none-any.whl (22 kB)\n",
      "Collecting argon2-cffi-bindings\n",
      "  Using cached argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
      "Collecting attrs>=17.4.0\n",
      "  Using cached attrs-22.1.0-py2.py3-none-any.whl (58 kB)\n",
      "Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\n",
      "  Using cached pyrsistent-0.18.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (115 kB)\n",
      "Collecting cffi>=1.0.1\n",
      "  Using cached cffi-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (441 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Using cached soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
      "Collecting webencodings\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Collecting pycparser\n",
      "  Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "Using legacy 'setup.py install' for sklearn, since package 'wheel' is not installed.\n",
      "Installing collected packages: webencodings, tokenizers, Send2Trash, pytz, mistune, ipython-genutils, fastjsonschema, urllib3, tinycss2, threadpoolctl, terminado, soupsieve, scipy, regex, pyyaml, pyrsistent, pycparser, prometheus-client, pandocfilters, MarkupSafe, lxml, jupyterlab-widgets, jupyterlab-pygments, joblib, idna, filelock, defusedxml, charset-normalizer, certifi, bleach, attrs, scikit-learn, requests, pandas, jsonschema, jinja2, cffi, beautifulsoup4, sklearn, nbformat, huggingface-hub, argon2-cffi-bindings, transformers, nbclient, argon2-cffi, nbconvert, notebook, widgetsnbextension, ipywidgets\n",
      "  Running setup.py install for sklearn ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed MarkupSafe-2.1.1 Send2Trash-1.8.0 argon2-cffi-21.3.0 argon2-cffi-bindings-21.2.0 attrs-22.1.0 beautifulsoup4-4.11.1 bleach-5.0.1 certifi-2022.6.15 cffi-1.15.1 charset-normalizer-2.1.0 defusedxml-0.7.1 fastjsonschema-2.16.1 filelock-3.8.0 huggingface-hub-0.8.1 idna-3.3 ipython-genutils-0.2.0 ipywidgets-7.7.1 jinja2-3.1.2 joblib-1.1.0 jsonschema-4.10.0 jupyterlab-pygments-0.2.2 jupyterlab-widgets-1.1.1 lxml-4.9.1 mistune-0.8.4 nbclient-0.6.6 nbconvert-6.5.3 nbformat-5.4.0 notebook-6.4.12 pandas-1.4.3 pandocfilters-1.5.0 prometheus-client-0.14.1 pycparser-2.21 pyrsistent-0.18.1 pytz-2022.2.1 pyyaml-6.0 regex-2022.7.25 requests-2.28.1 scikit-learn-1.1.2 scipy-1.9.0 sklearn-0.0 soupsieve-2.3.2.post1 terminado-0.15.0 threadpoolctl-3.1.0 tinycss2-1.1.1 tokenizers-0.12.1 transformers-4.21.1 urllib3-1.26.11 webencodings-0.5.1 widgetsnbextension-3.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers pandas sklearn ipykernel ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now import necessary packages and objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from bastionai.client import Connection\n",
    "from bastionai.optimizer_config import Adam\n",
    "from bastionai.utils import MultipleOutputWrapper, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the dataset\n",
    "\n",
    "The dataset can be found at https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip.\n",
    "Unzip the archive to obtain the datset file:\n",
    "\n",
    "```\n",
    "$ unzip smsspamcollection.zip\n",
    "```\n",
    "\n",
    "Each row represent a sample, the label come first followed by a tab and the raw text:\n",
    "```\n",
    "ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
    "ham\tOk lar... Joking wif u oni...\n",
    "spam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
    "```\n",
    "\n",
    "We first load the data from the file into a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                    Ok lar... Joking wif u oni...\\n\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"./data/SMSSpamCollection\"\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "with open(file_path) as f:\n",
    "  for line in f.readlines():\n",
    "    split = line.split('\\t')\n",
    "    labels.append(1 if split[0] == \"spam\" else 0)\n",
    "    texts.append(split[1])\n",
    "df = pd.DataFrame({ \"label\": labels, \"text\": texts })\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then preprocess the data using DistilBERT's tokenizer and we obtain tensors ready to be fed to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "token_id = []\n",
    "attention_masks = []\n",
    "for sample in df.text.values:\n",
    "    encoding_dict = tokenizer.encode_plus(\n",
    "        sample,\n",
    "        add_special_tokens=True,\n",
    "        max_length=32,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    token_id.append(encoding_dict['input_ids']) \n",
    "    attention_masks.append(encoding_dict['attention_mask'])\n",
    "\n",
    "token_id = torch.cat(token_id, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(df.label.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's now time to split the data in a train and test sets and to wrap it inside Dataset and DataLoader objects for ease of use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ratio = 0.2\n",
    "\n",
    "train_idx, test_idx = train_test_split(\n",
    "    np.arange(len(labels)),\n",
    "    test_size=val_ratio,\n",
    "    shuffle=True,\n",
    "    stratify=labels\n",
    ")\n",
    "\n",
    "train_set = TensorDataset([\n",
    "    token_id[train_idx], \n",
    "    attention_masks[train_idx]\n",
    "], labels[train_idx])\n",
    "\n",
    "test_set = TensorDataset([\n",
    "    token_id[test_idx], \n",
    "    attention_masks[test_idx]\n",
    "], labels[test_idx])\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size=4)\n",
    "test_dataloader = DataLoader(test_set, batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the model for use with DP-SGD and Bastion AI\n",
    "\n",
    "We now turn to preparing the DistilBERT language model. As Hugging Face's models typically have several outputs (logits, loss, etc.) we use Bastion AI's utility wrapper for models with multiple outputs to select the sole output that corresponds with the logits. In fact, Bastion AI's server supports models with an arbitrtary number of inputs but only supports models with a single output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not display warnings about layer not initialized\n",
    "# with pretrained weights (classification layers, this is fine)\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased',\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    "    torchscript=True\n",
    ")\n",
    "model = MultipleOutputWrapper(model, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sending dataset and model and training on the server\n",
    "\n",
    "Before proceeding, we need to start a local Bastion AI server which can be achivied with the following commands,\n",
    "assuming you have a working rust toolchain (https://www.rust-lang.org/tools/install):\n",
    "\n",
    "```\n",
    "$ cd ../server/bastionai_app\n",
    "$ cargo run\n",
    "```\n",
    "\n",
    "Now that the server code has been compiled and the server has started, it's time to send the dataset and the model to the server.\n",
    "\n",
    "We first use the `RemoteDataLoader` function to send our train and test dataloaders to the server (what we really send are the dataset and the dataloading parameters, not the dataloaders per se) and we provide a name and description to better identify them.\n",
    "\n",
    "Second, we use the `RemoteLearner` function to send the model to server and to set all the necessary training config.\n",
    "As training will be executed remotely, we need to script the model prior to sending it (i.e. compile it to Torch Script) which is automatically done in the `RemoteLearner` constructor. In case the model is not suited for scripting, which is generally the case with Hugging Face's models, the constructor automatically resorts to use tracing, which means the model is run locally on a small but representative input and the torch jit compiler tracks all functions that are called and compiles them on the fly. This approach, although more error prone (in certain cases the input may not activate some needed computation paths) is less picky that scripting and accepts nearly all models.\n",
    "\n",
    "In addition, as we'll use the DP-SGD algorithm for training, the constructor will also make the model compatible with Bastion AI's DP-SGD implementation. Unlike Opacus that uses backprop hooks to compute per-sample gradients, Bastion AI relies on normal autograd and modified layers that internally store expanded gradients (weight tensors have the same size in memory but are manipulated through expanded views that repeat them as many times as there are samples in a batch so that the gradient of these views are per-sample gradients). Per-samples gradient computation is key to DP-SGD and is one ingredient that make DP usable with Deep Learning models.\n",
    "\n",
    "To start training, we just call the `fit` method on the `RemoteLerner` object with appropriate number of epochs and DP budget. We can optionally override some of the learner's settings such as the learning rate or the clipping factor.\n",
    "\n",
    "We may finally retrieve a local copy of the trained model once the training is complete with the `get_model` method and test the model directly on the server with the `test` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 - train:   3%|▌                   | 28/1114 [00:53<36:48,  2.03s/batch, loss (cross_entropy)=0.6761] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/dhalf/Documents/bastionai/examples/distilbert_example_notebook.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/examples/distilbert_example_notebook.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m remote_dataloader \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mRemoteDataLoader(train_dataloader, test_dataloader, \u001b[39m\"\u001b[39m\u001b[39mSMSSpamCollection\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/examples/distilbert_example_notebook.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m remote_learner \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mRemoteLearner(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/examples/distilbert_example_notebook.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     model,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/examples/distilbert_example_notebook.ipynb#X21sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     remote_dataloader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/examples/distilbert_example_notebook.ipynb#X21sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     model_description\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDistilBERT\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/examples/distilbert_example_notebook.ipynb#X21sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/examples/distilbert_example_notebook.ipynb#X21sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m remote_learner\u001b[39m.\u001b[39;49mfit(nb_epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, eps\u001b[39m=\u001b[39;49m\u001b[39m2.0\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/examples/distilbert_example_notebook.ipynb#X21sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m remote_learner\u001b[39m.\u001b[39mtest(metric\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dhalf/Documents/bastionai/examples/distilbert_example_notebook.ipynb#X21sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m trained_model \u001b[39m=\u001b[39m remote_learner\u001b[39m.\u001b[39mget_model()\n",
      "File \u001b[0;32m~/Documents/bastionai/client/bastionai/learner.py:138\u001b[0m, in \u001b[0;36mRemoteLearner.fit\u001b[0;34m(self, nb_epochs, eps, max_grad_norm, lr)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    133\u001b[0m     nb_epochs: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     lr: Optional[\u001b[39mfloat\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    137\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 138\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mtrain(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_config(nb_epochs, eps, max_grad_norm, lr))\n",
      "File \u001b[0;32m~/Documents/bastionai/client/bastionai/client.py:158\u001b[0m, in \u001b[0;36mClient.train\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m, config: TrainConfig) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     \u001b[39m\"\"\"Trains a model with `TrainConfig` configuration on BastionAI.\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \n\u001b[1;32m    154\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[39m        config (TrainConfig):\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39m            Training configuration to pass to BastionAI.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m     metric_tqdm_with_epochs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstub\u001b[39m.\u001b[39;49mTrain(config), name\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mloss (\u001b[39;49m\u001b[39m{\u001b[39;49;00mconfig\u001b[39m.\u001b[39;49mmetric\u001b[39m}\u001b[39;49;00m\u001b[39m)\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/bastionai/client/bastionai/utils.py:303\u001b[0m, in \u001b[0;36mmetric_tqdm_with_epochs\u001b[0;34m(metric_stream, name)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n\u001b[1;32m    302\u001b[0m t \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 303\u001b[0m \u001b[39mfor\u001b[39;00m metric \u001b[39min\u001b[39;00m metric_stream:\n\u001b[1;32m    304\u001b[0m     \u001b[39mif\u001b[39;00m t \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m         t \u001b[39m=\u001b[39m new_tqdm_bar(\u001b[39m1\u001b[39m, metric\u001b[39m.\u001b[39mnb_epochs, metric\u001b[39m.\u001b[39mnb_batches)\n",
      "File \u001b[0;32m~/Documents/bastionai/client/venv/lib/python3.10/site-packages/grpc/_channel.py:426\u001b[0m, in \u001b[0;36m_Rendezvous.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 426\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next()\n",
      "File \u001b[0;32m~/Documents/bastionai/client/venv/lib/python3.10/site-packages/grpc/_channel.py:817\u001b[0m, in \u001b[0;36m_MultiThreadedRendezvous._next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_response_ready\u001b[39m():\n\u001b[1;32m    812\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state\u001b[39m.\u001b[39mresponse \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m\n\u001b[1;32m    813\u001b[0m             (cygrpc\u001b[39m.\u001b[39mOperationType\u001b[39m.\u001b[39mreceive_message\n\u001b[1;32m    814\u001b[0m              \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state\u001b[39m.\u001b[39mdue \u001b[39mand\u001b[39;00m\n\u001b[1;32m    815\u001b[0m              \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state\u001b[39m.\u001b[39mcode \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m--> 817\u001b[0m _common\u001b[39m.\u001b[39;49mwait(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_state\u001b[39m.\u001b[39;49mcondition\u001b[39m.\u001b[39;49mwait, _response_ready)\n\u001b[1;32m    818\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state\u001b[39m.\u001b[39mresponse \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    819\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state\u001b[39m.\u001b[39mresponse\n",
      "File \u001b[0;32m~/Documents/bastionai/client/venv/lib/python3.10/site-packages/grpc/_common.py:141\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(wait_fn, wait_complete_fn, timeout, spin_cb)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m wait_complete_fn():\n\u001b[0;32m--> 141\u001b[0m         _wait_once(wait_fn, MAXIMUM_WAIT_TIMEOUT, spin_cb)\n\u001b[1;32m    142\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m+\u001b[39m timeout\n",
      "File \u001b[0;32m~/Documents/bastionai/client/venv/lib/python3.10/site-packages/grpc/_common.py:106\u001b[0m, in \u001b[0;36m_wait_once\u001b[0;34m(wait_fn, timeout, spin_cb)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wait_once\u001b[39m(wait_fn, timeout, spin_cb):\n\u001b[0;32m--> 106\u001b[0m     wait_fn(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    107\u001b[0m     \u001b[39mif\u001b[39;00m spin_cb \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    108\u001b[0m         spin_cb()\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[1;32m    325\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "with Connection(\"[::1]\", 50051, default_secret=b\"secret\") as client:\n",
    "    remote_dataloader = client.RemoteDataLoader(train_dataloader, test_dataloader, \"SMSSpamCollection\")\n",
    "    \n",
    "    remote_learner = client.RemoteLearner(\n",
    "        model,\n",
    "        remote_dataloader,\n",
    "        metric=\"cross_entropy\",\n",
    "        optimizer=Adam(lr=5e-5),\n",
    "        model_description=\"DistilBERT\",\n",
    "    )\n",
    "\n",
    "    remote_learner.fit(nb_epochs=2, eps=2.0)\n",
    "    remote_learner.test(metric=\"accuracy\")\n",
    "    \n",
    "    trained_model = remote_learner.get_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6993cb9073eaa1097b6e3b6529d06c5840b05bad16c8a47177ac9bf16f0b1e0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
